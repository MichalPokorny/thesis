\chapter{Splay trees}
\label{chapter:splay}
Splay trees are a well-known variant of binary search trees introduced
by \cite{splay} that adjust their structure with every operation, including
lookups. Splay tree operations take $\O(\log N)$ amortized time, which is
similar to common balanced trees, like AVL trees or red-black trees.

However, unlike BSTs, splay trees adjust their structure
according to the access pattern, and a family of theorems proves that
various non-random access patterns are fast on splay trees.
According to the \emph{static optimality theorem}, the running time
of a sufficiently long sequence of \textsc{Find} operations on a splay tree
is within a constant factor of an optimal static search tree.
The \emph{working set theorem} proves that the speed of accessing keys in
any small \emph{working set} depends only on the logarithm of the size
of the working set.
Finally, the \emph{dynamic finger theorem} claims that splay trees are also
fast when accessing keys that are numerically close to recently accessed keys.
All of these results are implied by the unproven \emph{dynamic optimality
conjecture}, which proposes that splay trees are dynamically optimal binary
search trees: if a dynamic binary search tree optimally tuned for an access
sequence $S$ needs $\mathrm{OPT}(S)$ operations to perform the accesses, splay
trees are presumed to only need $\O(\mathrm{OPT}(S))$ steps.

Let us also denote stored keys as $K_1,\ldots K_N$ in sorted order.
Splay trees are binary search trees, so they are composed of nodes, each of
which contains one key and its associated value. A node has up to two children,
denoted \emph{left} and \emph{right}.
The left subtree of a node with key $K_i$ contains only keys smaller than $K_i$
and, symetrically, the right subtree contains only keys larger than $K_i$.

Splay trees are maintained via a heuristic called \emph{splaying}, which
moves a specified node $x$ to the root of the tree by performing a sequence
of edge rotations along the path from the root to $x$.
Rotations cost $\O(1)$ time each and rotating any edge maintains
the soundness of search trees. Rotations are defined by figure
\ref{fig:rotation}.

\newcommand{\hunk}[2]{ node [splay_hunk] (hunk#1-#2) {#1} }

\begin{figure}
\centering
% TODO: DRY
\begin{tikzpicture}[
	splay_node/.style = {align=center, inner sep=0pt, text centered, circle,
	font=\sffamily, draw=black, text width=1.2em},
	triangle/.style = {regular polygon, regular polygon sides=3, scale=0.8, fill=white},
	splay_hunk/.style = {align=center, inner sep=0pt, text centered,
		triangle, font=\sffamily, draw=black, text width=1.2em}
]
\node [splay_node] at (0, 0) (x-b) {$x$}
child { node [splay_node] (y-b) {$y$}
	child { \hunk{1}{b} }
	child { \hunk{2}{b} }
}
child { \hunk{3}{b} };

\node [fit=(x-b) (y-b) (hunk1-b) (hunk2-b) (hunk3-b)] (Before) {};

\node [splay_node] at (6, 0) (y-a) {$y$}
child { \hunk{1}{a} }
child { node [splay_node] (x-a) {$x$}
	child { \hunk{2}{a} }
	child { \hunk{3}{a} }
};

\node [fit=(x-a) (y-a) (hunk1-a) (hunk2-a) (hunk3-a)] (After) {};
\path[->] ($(Before.east) + (+.5,+.5)$) edge node [above] {rotate right} ($(After.west)
+ (-.5,+.5)$);
\path[->] ($(After.west) - (+.5,+.5)$) edge node [below] {rotate left} ($(Before.east)
- (-.5,+.5)$);
\end{tikzpicture}
\caption{Left and right rotation of the edge between $x$ and $y$.}
\label{fig:rotation}
\end{figure}

To splay a node $x$, we perform \emph{splaying steps}, which
rotate edges between $x$, its parent $p$ and possibly its grandparent $g$
until $x$ becomes the root. Splaying a node of depth $d$ takes time $\Theta(d)$.
Up to left-right symmetry, there are three cases of splaying steps:

\begin{itemize}
\item[Case 1 (\emph{zig}):] If $p$ is the root, rotate the $px$ edge. (This case is terminal.)
\item[Case 2 (\emph{zig-zig}):] If $p$ is not the root and $x$ and
		$p$ are both left or both right children, rotate
		the edge $gp$, then rotate the edge $px$.
\item[Case 3 (\emph{zig-zag}):] If $p$ is not the root and $x$ is a left child and $p$
		is a right child (or vice versa), rotate the edge $px$ and
		then rotate the edge now joining $g$ with $x$.
\end{itemize}

\begin{figure}
\centering
% TODO: DRY
\begin{tikzpicture}[
	splay_node/.style = {align=center, inner sep=0pt, text centered, circle,
		font=\sffamily, draw=black, text width=1.2em},
	triangle/.style = {regular polygon, regular polygon sides=3, scale=0.8,
		fill=white},
	splay_hunk/.style = {align=center, inner sep=0pt, text centered,
		triangle, font=\sffamily, draw=black, text width=1.2em},
]
\node at (0,0) (ZigBefore) {
	\begin{tikzpicture}
	\node [splay_node] at (0,0) (p-b) {$p$}
	child { node [splay_node] (x-b) {$x$}
		child { \hunk{1}{b} }
		child { \hunk{2}{b} }
	}
	child { \hunk{3}{b} };
	\end{tikzpicture}
};
\node at (6,0) (ZigAfter) {
	\begin{tikzpicture}
	\node [splay_node] at (0,0) (x-a) {$x$}
	child { \hunk{1}{a} }
	child { node [splay_node] (p-a) {$p$}
		child { \hunk{2}{a} }
		child { \hunk{3}{a} }
	};
	\end{tikzpicture}
};
\path[->] (2.5,0) edge node [above] {zig} (3.5,0);
\node at (0,-5) (ZigZigBefore) {
	\begin{tikzpicture}[]
	\node [splay_node] at (0,0) (g-b) {$g$}
	child { node [splay_node] (p-b) {$p$}
		child { node [splay_node] (x-b) {$x$}
			child { \hunk{1}{b} }
			child { \hunk{2}{b} }
		}
		child { \hunk{3}{b} }
	}
	child { \hunk{4}{b} };
	\end{tikzpicture}
};
\node at (6,-5) (ZigZigAfter) {
	\begin{tikzpicture}[]
	\node [splay_node] at (0,0) (x-a) {$x$}
	child { \hunk{1}{a} }
	child { node [splay_node] (p-a) {$p$}
		child { \hunk{2}{a} }
		child { node [splay_node] (g-a) {$g$}
			child { \hunk{3}{a} }
			child { \hunk{4}{a} }
		}
	};
	\end{tikzpicture}
};
\path[->] (2.5,-5) edge node [above] {zig-zig} (3.5,-5);
\node at (0,-11) (ZigZagBefore) {
	\begin{tikzpicture}[]
	\node [splay_node] at (0,0) (g-b) {$g$}
	child { node [splay_hunk] (hunk1-b) {1} }
	child { node [splay_node] (p-b) {$p$}
		child { node [splay_node] (x-b) {$x$}
			child { \hunk{2}{b} }
			child { \hunk{3}{b} }
		}
		child { \hunk{4}{b} }
	};
	\end{tikzpicture}
};
\node at (6,-11) (ZigZagAfter) {
	\begin{tikzpicture}[]
	%\node [splay_node] at (6,-0.75) (x-a) {$x$}
	\node [splay_node] at (0,0) (x-a) {$x$}
	[sibling distance=2.5cm]
	child { node [splay_node] (g-a) {$g$}
		[sibling distance=1.2cm]
		child { \hunk{1}{a} }
		child { \hunk{2}{a} }
	}
	child { node [splay_node] (p-a) {$p$}
		[sibling distance=1.2cm]
		child { \hunk{3}{a} }
		child { \hunk{4}{a} }
	};
	\end{tikzpicture}
};
\path[->] (2.5,-11) edge node [above] {zig-zag} (3.5,-11);
\end{tikzpicture}

\caption{The cases of splay steps.}
%\label{fig:splay-step}
\end{figure}

% Splaying reduces the depth of every node along the access path by roughly
% one half. TODO: fakt? TODO: figure

To \textsc{Find} a key $K_F$ in a splay tree, we use binary search as in any
binary search tree: in every node, we compare its key $K_i$ with $K_F$, and
if $K_i \neq K_F$, we continue to the left subtree or to the right subtree.
If the subtree we would like to descend into is empty, the search is aborted,
since $K_F$ is not present in the tree.
After the search finishes (successfully or unsuccessfully), we splay the last
visited node. An \textsc{Insert} is similar: we find the right place for the
new node, insert it, and finally splay it up.

\textsc{Delete}s are slightly more complex. We first find and splay the node $x$
that we need to delete. If $x$ has one child after splaying, we delete it and
replace it by its only child. One possible way to handle the case of two
children is finding the rightmost node $x^-$ in $x$'s left subtree and splaying
it just below $x$. By definition, $x^-$ is the largest in $x$'s left subtree,
so it must have no right child after splaying below $x$. We delete $x$ and link
its right subtree below $x^-$.

\section{Time complexity bounds}
For the purposes of analysis, we assign a fixed positive weight $w(K_i)$
to every key $K_i$. Setting $w(K_i)$ to $1/N$ allows us to prove that
the amortized complexity of the splay operation is $\O(\log N)$, which implies
that splay tree \textsc{Find}s and updates also take amortized logarithmic time.
Proofs of further complexity results will use the same similar analysis with
other assignments of $w$.

Let us denote the subtree rooted at a node $x$ as $T[x]$
and the key stored in $x$ as $T(x)$. Define the size $s(x)$ of a node $x$ as
$\sum_{y\in T[x]} w(T(y))$ and the rank $r(x)$ as $\log s(x)$.
For amortization, let us define the potential $\Phi$ of the tree to be the sum
of the ranks of all its nodes. In a sequence of $M$ accesses, if the $i$-th
access takes time $t_i$, define its amortized time $a_i$ to be
$t_i+\Phi_{i-1}-\Phi_{i}$. Expanding and telescoping the total access time
yields $\sum_{i=1}^M t_i=\Phi_0-\Phi_M+\sum_{i=1}^m a_i$.

We will bound the magnitude of every $a_i$ and of the total potential drop
$\Phi_0-\Phi_M$ to obtain an upper bound on $\sum_{i=1}^M t_i$.
Since every rotation can be performed in $\O(1)$
pointer assignments, we can measure the time to splay a node in the number
of rotations performed (or 1 if no rotations are needed).

\begin{lemma}
The amortized time $a$ to splay a node $x$ in a tree with root $t$
is at most $3(r(t)-r(x))+1 = \O(\log(s(t)/s(x)))$.
\end{lemma}
\begin{proof}
If $x=t$, we need no rotations and the cost of splaying is 1.
Assume that  $x\neq t$, so at least one rotation is needed.
Consider the $j$-th splaying step.
Let $s$ and $s'$, $r$ and $r'$ denote the size and rank functions just before
and just after the step, respectively. We show that the amortized time
$a_j$ for the step is at most $3(r'(x)-r(x))+1$ in case 1
and at most $3(r'(x)-r(x))$ in case 2 or case 3. Let $p$ be the original parent
of $x$ and $g$ the original grandparent of $x$ (if it exists).

\begin{itemize}
\item[Case 1 (\emph{zig}):]
	The only needed rotation of the $px$ edge may only change the rank of
	$x$ and $p$, so $a_j=1+r'(x)+r'(p)-r(x)-r(p)$.
	Because $r(p)\geq r'(p)$, we also have $a_j\leq 1+r'(x)-r(x)$.
	Furthermore, $r'(x)\geq r(x)$, so $a_j\leq 1+3(r'(x)-r(x))$.

\item[Case 2 (\emph{zig-zig}):]
	The two rotations may change the rank of $x$, $p$ and $g$,
	so $a_j=2+r'(x)+r'(y)+r'(z)-r(x)-r(y)-r(z)$. The zig-zig step
	moves $x$ to the original position of $g$, so $r'(x)=r(g)$.
	Before the step, $x$ was $p$'s child, and after the step,
	$p$ was $x$'s child, so $r(x)\leq r(p)$ and $r'(p)\leq r'(x)$.
	Thus $a_j\leq 2+r'(x)+r'(g)-2r(x)$.
	We claim that this is at most $3(r'(x)-r(x))$, that is, that
	$2r'(x)-r(x)-r(g)\geq 2$.

	$2r'(x)-r(x)-r'(g)=-\log\frac{s(x)}{s'(x)}-\log\frac{s'(g)}{s'(x)}$.
	We have $s(x)+s'(g)\leq s'(x)$.

	If $p,q\geq 0$ and $p+q\leq 1$, $\log p+\log q$ is maximized
	by setting $p=q=\frac{1}{2}$, which yields $\log p+\log q=-2$.
	% TODO: which inequality above?
	Thus $2r'(x)-r(x)-r(g)\geq 2$ and $a_j \leq 3(r'(x)-r(x))$.

\item[Case 3 (\emph{zig-zag}):]
	The amortized time of the zig-zag step is
	$a_j=2+r'(x)+r'(p)+r'(g)-r(x)-r(p)-r(g)$. $r'(x)=r(g)$ and $r(x)\leq r(p)$,
	so the time is $\leq 2+r'(p)+r'(g)-2r(x)$.
	We claim that this is at most $2(r'(x)-r(x))$,
	i.e.\ $2r'(x)-r'(p)-r'(g)\geq 2$. This can be proven
	similarly to case 2 from the inequality $s'(p)+s'(g)\leq s'(x)$.
	Thus the $a_j \leq 2(r'(x)-r(x))\leq 3(r'(x)-r(x))$.
\end{itemize}

Telescoping $\sum a_j$ along the splayed path yields an upper bound of
$a \leq 3(r'(t)-r(x))+1$ for the entire splaying operation.
\end{proof}

Note that over any sequence of splay operations
% TODO: key vs. node assignment: w(i)
the potential $\Phi$ may only drop by up to $\sum_{i=1}^N \log(W/w(K_i))$
where $W=\sum_{i=1}^N w(K_i)$, since the size of the node containing $K_i$
must be between $w(K_i)$ and $W$.

\begin{theorem}[Balance Theorem]
A sequence of $M$ splay operations on a splay tree with $N$ nodes takes time
$\O((M+N)\log N+M)$.
\end{theorem}
\begin{proof}
Assign $w(K_i)=1/N$ to every key $K_i$. The amortized
access time for any key is at most $3\log N+1$. We have $W=1$, so by
the previous observation the potential drops by at most $N\log N$ over
the access sequence. Thus the time to perform the access sequence is at most
$(3\log N+1)M + N\log N = \O((M+N)\log N + M)$.
\end{proof}

The balance theorem states that on a sufficiently long sequence, lookups in
a splay tree are as efficient as in any static search tree, including
usual balancing search trees (like AVL or red-black trees).

For any key $K_i$, let $q(K_i)$ be the number of occurences of $K_i$
in an access sequence.
\begin{theorem}[Static Optimality Theorem]
If every key is accessed at least once, the the total access time is
$\O(M + \sum_{i=1}^N q(K_i)\log\frac{M}{q(K_i)})$.
\end{theorem}
\begin{proof}
Assign a weight of $q(i)/M$ to every key $i$. For any key $i$, its
amortized time per access is $3(r(t)-r(x))+1=-3r(x)+1=-3\log(s(x))+1\leq
	-3\log(w(x))+1=O(\log(M/q(i)))$.
Since $W=1$, the net potential drop over the sequence is at most
$\sum_{i=1}^{N}\log(M/q(i))$. The result follows.
\end{proof}

Note that the time to perform the access sequence is equal to
$\O(M \cdot (1 + H(P)))$, where $H(P)$ is the entropy of the access probability
distribution defined as $P(i)=q(i)/M$. All static trees must take time
$\Omega(M\cdot (1+H(P)))$ for the access sequence, so splay trees are statically
optimal. A proof of this lower bound is available in \cite{information-theory}.

Let us denote the indices of accessed keys in an access sequence $S$ as
$k_1, \ldots k_M$ so that $S=(K_{k_i})_{i=1}^M$.

\begin{theorem}[Static Finger Theorem]
Given any chosen key $K_f$, the total access time is
$\O(N\log N + M + \sum_{j=1}^M \log(|k_j-f|+1))$.
\end{theorem}
\begin{proof}
	% TODO: proof missing here
\end{proof}

As proven in \cite{dynamic-finger-1} and \cite{dynamic-finger-2},
accessing keys numerically close to recently accessed keys is also fast:
\begin{theorem}[Dynamic Finger Theorem]
The cost of performing an access sequence is
$\O(N+M+\sum_{i=2}^M \log(|k_i-k_{i-1}| + 1))$.
\end{theorem}

For any $j\in\{1,\ldots M\}$, define $t(j)$ to be the number of distinct
keys accessed since the last access of key $K_{k_j}$. If $K_{k_j}$ was not
accessed before, $t(j)$ is picked to be the number of distinct keys accessed
so far.
\begin{theorem}[Working Set Theorem]
The total access time is $\O(N\log N + M + \sum_{j=1}^M\log(t(j)+1))$.
\end{theorem}
\begin{proof}
	% TODO: proof missing here
\end{proof}

The working set theorem implies that most recently accessed keys (the
``working set'') are cheap to access, which makes splay trees behave well when
the access pattern exhibits temporal locality.

The dynamic optimality conjecture, which states that splay trees are
$\O(1)$ competitive compared to any dynamic search tree, is an open problem.
Since \cite{splay}, it was well-known that splay trees are
$\O(\log N)$-competitive.

\section{Alternate data structures}
\cite{tango} proposed building alternative search trees with small
non-constant competitive factors, and invented the \emph{tango tree}, which
is $\O(\log\log N)$ competitive. However, worst-case performance of tango trees
is not very good: on pathological sequences, they underperform plain BSTs
by a factor of $\O(\log\log N)$.
\cite{chain-splaying} extends splaying with some housekeeping operations
below the splayed element and proves that this \emph{chain-splay} heuristic
in $\O(\log\log N)$ competitive.

Finally, \cite{multisplay-trees} presents \emph{multi-splay trees}.
Multi-splay trees are $\O(\log\log N)$-competitive and they have all important
proven properties of splay trees. They also satisfy the \emph{deque property}
($\O(M)$ time for $M$ double-ended queue operations), which is only conjectured
to apply to splay trees.
Unlike tango trees, they have an amortized access time of $\O(\log N)$.
While an access in splay trees may take time up to $\O(N)$, multi-splay trees
guarantee a more desirable worst-case access time of $\O(\log^2 N)$.
\section{Implementation}
% TODO: top-down splay

\section{Top-down splaying}
Simple implementations of splaying first find the node to splay, and then
splay along the traversed path. The traversed path may be either kept
in an explicit stack, which is progressively shortened by splay steps,
or the tree may be augmented with pointers to parent nodes.
Explicitly keeping a stack is wasteful, because it requires dynamically
allocating up to $N$ node pointers when splaying. On the other hand,
storing parent pointers makes nodes less memory-efficient, especially
with small sizes of keys.

A common optimization is \emph{top-down splaying}, which simulates
splaying while searching.
% TODO
% The tree is traversed 2 nodes at a time, and
% two trees $L$ and $R$ are maintained. Encountered branches smaller than
% the sought key are put under the $L$ tree, and branches 

\section{Applications}
A drawback of splay trees is that accessing the $\O(\log N)$ amortized
nodes on the access path may incur an expensive cache miss for every node --
splay trees make no effort to exploit the memory hierarchy.
In contrast, lookups in B-trees and cache-oblivious B-trees
only cause up to $\Theta(\log_B N)$ cache misses, which is a multiplicative
improvement of $\log B$.

On the other hand, splaying automatically adjusts the structure of the splay
tree to speed up access to recently or frequently accessed nodes. By the
working set theorem, accessing a small set of keys is always fast, no matter
how big the splay tree is. While B-trees and cache-oblivious B-trees are
also faster on smaller working sets, the complexity of any access remains
$\O(\log_B N)$, so accessing a small working set is slower on larger
dictionaries.

Splay trees are frequently used in practice where access patterns are assumed
to be non-random. For example, splay trees are used in the FreeBSD kernel
to store the mapping from virtual memory areas to
addresses\cite{freebsd-vm-splay}. % TODO: The citation looks horrible.
% TODO: The citation is also probably incorrect. Check the standard.
Unfortunately, splay trees are much slower than BSTs on less
regular access patterns: splaying always performs costly memory writes.
For some applications (e.g.\ real-time systems), worst-case $\O(N)$ performance
is also unacceptable (especially if the splay tree stores data entered by
an adversary).
