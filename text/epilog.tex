\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

We confirmed that cache-oblivious B-trees are practically competitive with
more common data structures in main memory, especially on larger dictionaries
with frequent \textsc{Find}s and uniform access patterns.

Our implementation of $k$-splay trees and $k$-forests performed badly.
In our opinion, they alone are not a practical replacement for simple splay
trees. A more optimized implementation of $k$-splaying might reach parity with
splay trees.

Experiments on data recorded from Mozilla Firefox suggest that splay trees
and cuckoo hash tables do well on most dictionaries as they are practically
used. A particularly interesting conclusion that can be drawn from
Table~\ref{tab:firefox-results} is that hashing with linear probing may
be (somewhat counterintuitively) slower than splay trees.
Larger databases that require order queries also seem to be best served
by splay trees, followed by cache-oblivious \mbox{B-trees} and cache-aware
\mbox{B-trees}.

\section*{Suggestions for further research}
The dictionary problem is well-explored, including structures for efficient
in particular models of computation and practical libraries for real computers.
The space-time limitations of this thesis unfortunately did not permit us to
completely survey all of them.

We believe an benchmarking various non-traditional self-adjusting structures,
like Tango trees from \cite{tango} or multi-splay trees from
\cite{multisplay-trees}, could give interesting results. Splay trees are very
performant on practical access patterns, but their worst-case $\O(N)$ behavior
limits their usefulness in time-sensitive systems. Some self-adjusting
structures provide better worst-case access times (e.g.\ $\O(\log N)$ in
multi-splay trees. On the other hand, the implementation of splay trees
are considerably simpler, so the complexity of operations might outweight
time saved by fewer cache misses in the worst case.

Several data structures based on tries have also been proposed for the
dictionary problem. One example are \emph{y-fast tries} \cite{y-fast},
which allow \textsc{Find}s in time $\O(1)$ and updates and predecessor/successor
queries in time $\O(\log\log |U|)$, where $U$ is the key universe. They require
$\O(N \log\log |U|)$ memory.
The RAM model is required by y-fast tries -- they assume that RAM operations
can be performed on keys in constant time.
The original motivation for developing y-fast tries was lowering the memory
requirements of van Emde Boas queues ($\O(|U|)$) while keeping the same time
for operations.
% TODO: Try to find some practical numbers.

\emph{Judy arrays} are highly optimized dictionaries developed at
Hewlett-Packard \cite{judy-shop-manual, judy-patent}.
HP sources claim that Judy arrays are very efficient in practice.
The data structure is based on sparse 256-ary tries with implementation tricks
that compress the representation.
Unfortunately, we found the existing documentation highly complex and sometimes
incomplete. On the other hand, an open-source implementation is available
at \url{http://judy.sourceforge.net/}, so it should be possible to independently
analyze the data structure and possibly to improve upon it.
