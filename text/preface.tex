\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

It is a well-known fact that there is a widening gap between
the performance of CPUs and memory. As an optimization of memory accesses,
modern computers include several small and fast caches between the CPU and
main memory. However, if programs access data mostly randomly, I/O can become
the performance bottleneck, even for programs running in main memory.

Standard models of computation only measure the performance of algorithms
in the number of CPU instructions executed and the number of memory cells used.
These models aren't well suited for environments where different memory cells
may have vastly different access speeds, for example depending on which caches
currently hold the memory cell. The \emph{external memory model} is a simple
extension of the RAM model that adds a \emph{block transfer} measure, which
is the number of \emph{blocks} transferred between a fast cache and a slow
\emph{external memory}. While this model was originally developed
in the context of accessing data stored or hard disks, it is also useful
for reasoning about data transfers between the CPU and main memory.

\emph{Cache-oblivious algorithms} are a class of external memory algorithms
that perform equally well given any cache size and block size. Thanks to this
property, they need little tuning for efficient implementation.
Modern CPU architectures perform various optimizations that can change
the effective size of a block, so tuning an algorithm by setting a good block
size might be difficult.
The external memory model and cache-oblivious algorithms are introduced futher
in chapter \ref{chapter:models}.

This thesis explores the performance implications of memory hierarchies
on data structures implementing dictionaries or sorted dictionaries.
Especially unsorted dictionaries are very common in practice, as illustrated
by modern programming languages, which commonly have a dedicated built-in
data type for unsorted dictionaries (e.g.\ \texttt{std::unordered\_map} in C++,
\texttt{dict} in Python, or hashes in Perl).

Dictionaries maintain a set of key-value pairs with distinct keys.
The \textsc{Find} operation find the value associated with a given key, or
it reports that no such value exists. \textsc{Insert} inserts a new
key-value pair and \textsc{Delete} removes a key-value pair given its key.
Sorted dictionaries additionally maintain an ordering on the keys and they
allow \textsc{FindNext} and \textsc{FindPrevious} operations.
Given a key $k$, which may or may not be present in the dictionary,
\textsc{FindNext} and \textsc{FindPrevious} find the closest larger or smaller
key present in the dictionary.

The most common data structure implementing an unsorted dictionary is a hash
table. We describe some variants of hash tables in chapter \ref{chapter:hashing}.
Most hash tables have expected $\O(1)$ time for all operations, which
makes them quite practical. On the other hand, there is no simple way to
implement sorted dictionaries efficiently via hash tables.

Ordered dictionaries are usually maintained in search trees. Common variants
of search trees include AVL trees, red-black trees, B-trees or splay trees.
AVL trees, red-black trees and B-trees are \emph{balanced} -- a design
invariant maintains their height low, which makes operations cost $\O(h)$, where
$h$ is the height of the tree. AVL trees and red-black trees are binary,
so $h=\O(\log N)$ (all logarithms in this thesis are in base 2, unless stated
otherwise). B-trees store $b\geq 2$ keys per node and they maintain all leaves
at the same depth, so operations on B-trees touch $\O(\log_b N)$ nodes.

Splay trees are binary search trees with a self-adjusting rule.
The structure of a splay tree depends not only on the sequence of
\textsc{Insert}s and \textsc{Delete}s, but also on executed \textsc{Find}s.
The self-adjusting rule (\emph{splaying}) puts recently accessed nodes
near the root, so \textsc{Find}s on frequently or recently accessed keys
are faster than in balanced trees. On the other hand, splaying can put
the splay tree in a degenerate state, in which accessing an unlucky node can
cost up to $\O(N)$ node reads. Fortunately, the amortized number of node
reads per \textsc{Find} turns out to be $\O(\log N)$.

Splay trees are good at storing nonuniformly accessed dictionaries, but
the expected number of nodes read to \textsc{Find} a key is generally a factor
of $\O(\log b)$ higher than in B-trees. We explore and implement two
data structures designed to both perform well on non-uniform access patterns
and to perform less I/O: \emph{$k$-splay trees} in chapter
\ref{chapter:ksplay} and \emph{$k$-forests} in chapter \ref{chapter:kforest}.

In chapter \ref{chapter:cob}, we describe \emph{cache-oblivious B-trees}.
The number of memory operations for cache-oblivious B-tree operations
is within a constant factor of the bounds given by a B-tree optimally tuned
for the memory hierarchy. In practice, we found the performance of
cache-oblivious B-trees to be quite competitive, especially on large datasets
with uniform access patterns.

The chapters on hashing and cache-oblivious B-trees are based on the Advanced
Data Structures course as taught by Erik Demaine on MIT in spring 2012.
Lecture videos and other materials are available at MIT OpenCourseWare\footnote{
\url{http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-851-advanced-data-structures-spring-2012/index.htm}}.

\section{Notation}
In this thesis, logarithms are in base 2 unless stated otherwise.
Chapter \ref{chapter:cob} uses the \emph{hyperfloor} operation
$\lhfloor x\rhfloor$, which is defined as $2^{\lfloor\log x\rfloor}$.
