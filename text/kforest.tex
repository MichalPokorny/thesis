\chapter{$k$-forests}
% TODO: try $k$-forests based on cache-oblivious B-trees
The performance of $k$-splay trees may suffer on access sequences chosen
by an adversary, because it is known that certain access sequences must
take $\O(\log N)$ block transfers per element.
In \citeyear{martel}, \citeauthor{martel} developed \textit{$k$-forests} --
a self-adjusting dictionary data structure based on a sequence of
$k$-ary search trees of increasing size.

The $k$-forest allows \textsc{Find}, \textsc{Insert} and \textsc{Delete}
operations in worst-case, optionally randomized $\O(\log_k N)$ block transfers.
It can be proven that a generalization of the Static Optimality theorem
also applies to $k$-forests: an element with access probability $p$
will have average lookup time $\O\left(\min\{\log_k \frac{1}{p}, \log_k
N\}\right)$.

% TODO: and also working set theorem

On the other hand, $k$-forests do not have fast finger queries. Scanning
a $k$-forest in increasing key order takes $\Omega(N\log_k N)$. Furthermore,
all successor or predecessor queries take $\Omega(\log_k N)$ block transfers.

We are unaware of any data structure providing good speed for both static
searches and finger queries with a $\log_B$ reduction in block transfers
over splay trees.

A $k$-forest containing $N$ elements is a sequence of $\O(\log_k N)$ $k$-ary
search trees $T_1, T_2, \ldots$. Each tree $T_i$ contains up to $s(i)$ key-value
pairs, where $s(i) = k^{2^i} - 1$. The trees need to support $\O(\log_k s(i))$
time, so B-trees are a natural choice.

Every tree, with the possible exception of the last one, is kept full,
so tree $T_1$ has height 1, $T_2$ has height 2, $T_3$ has height 4, and so on.
Each key-value pair inserted into the data structure is always kept in one
tree $T_i$. The self-adjusting operation moves elements between trees to
keep more recently or more frequently accessed elements in lower, smaller trees.

To \textsc{Find} a key, we scan the trees $T_i$ in increasing order of $i$.
If we scan all trees and find no matches, the search is unsuccessful.
Otherwise, the key-value pair is removed from its tree $T_i$ and inserted
into $T_0$. We then \textit{demote} one item from tree $T_0$ to $T_1$,
then from $T_1$ to $T_2$, and so on until all trees meet their size bounds.

\cite{martel} describes two implementations of \textit{demotion}.
The first one is a deterministic implementation named \textit{LRU demotion},
which maintains information about the time of last access to elements
in every tree. The element pushed down to the next tree is always the least
recently accessed one, so the trees $T_1,T_2,\ldots$ are maintained in sorted
order with respect to last access time.
A simpler implementation without auxilliary data is \textit{random demotion},
which simply selects a random key from $T_i$ to demote to $T_{i+1}$.
Both are equivalent in the sense that the expected time bounds arising
from random demotion equal the deteministic time bounds of LRU demotion.

\textsc{Insert} and \textsc{Delete} operations are similar to \textsc{Find}.
\textsc{Insert} inserts to $T_1$ and then demotes elements from $T_1,T_2,\ldots$
until the forest is fixed.
\textsc{Delete} finds the pair in its tree $T_i$ and removes it, and
then promotes items from all trees $T_{i+1},T_{i+2},\ldots$


