\chapter{$k$-forests}
\label{chapter:kforest}
The performance of $k$-splay trees may suffer on access sequences chosen
by an adversary: it is known that certain access sequences must
take $\Omega(\log N)$ block transfers per element.
A better worst-case block transfer bound of $\O(\log_k N)$ for \textsc{Find},
\textsc{Insert} and \textsc{Delete} operations is achieved by \emph{$k$-forests} \cite{martel}.
A $k$-forest is a self-adjusting dictionary data structure based on a sequence
of $k$-ary search trees of increasing size. A simpler randomized version
of $k$-forests achieves the same expected bound on block transfers.

It can be proven that a generalization of the Static Optimality theorem
also applies to $k$-forests: an element with access probability $p$
will have average lookup time $\O\left(\min\{\log_k \frac{1}{p}, \log_k
N\}\right)$. $k$-forests also have the working set property.

On the other hand, $k$-forests do not have fast finger queries. Scanning
the keys in a~\mbox{$k$-forest} in increasing order requires
$\Omega(N\log_k N)$ block transfers, as every predecessor or successor query
needs $\Omega(\log_k N)$ block transfers.

We are unaware of any data structure providing good speed for both static
searches and finger queries with a $\log_B$ reduction in block transfers
over splay trees.

A $k$-forest containing $N$ elements is a sequence of $\O(\log_k N)$ $k$-ary
search trees $T_1, T_2, \ldots$. Each tree $T_i$ contains up to $s(i)$ key-value
pairs, where $s(i) = k^{2^i} - 1$. The trees need to support \textsc{Insert}s
and \textsc{Delete}s in $\O(\log_k s(i))$ time, so \mbox{B-trees} with
$b=\O(k)$ are a natural choice for representing the trees.

Every tree, with the possible exception of the last one, is kept full,
so if we represent the trees as \mbox{B-trees}, then $T_1$ has height~1,
$T_2$ has height~2, $T_3$ has height~4, and so on.
Each key-value pair inserted into the data structure is always kept in one
tree $T_i$. The self-adjusting operation moves elements between trees to
keep more recently accessed elements in smaller trees that are faster
to access. A deterministic version of this operation keeps the $s(1)$ most
recently accessed items in tree $T_1$, then the next $s(2)$ most recently
accessed items in $T_2$, and so on.

To \textsc{Find} a key, we scan the trees $T_i$ in increasing order of $i$.
If we scan all trees and find no matches, the search is unsuccessful.
Otherwise, the key-value pair is removed from its tree $T_i$ and inserted
into $T_0$. We then \emph{demote} one item from tree $T_0$ to $T_1$,
then from $T_1$ to $T_2$, and so on until all trees meet their size bounds.

Demotion can be implemented deterministically, or randomly.
Deterministic, or \emph{LRU demotion}, maintains information about the time
of last access to elements in every tree. The element pushed down to the next
tree is always the least recently accessed one, so the trees $T_1,T_2,\ldots$
are maintained in sorted order with respect to last access time.
\emph{Random demotion} is simpler to implement and it requires no auxiliary
data: we simply select a random key from $T_i$ and demote it to $T_{i+1}$.
Both demotion approaches are equivalent in the sense that the expected time
bounds arising from random demotion equal the deterministic time bounds of
LRU demotion.

\textsc{Insert} and \textsc{Delete} operations are similar to \textsc{Find}.
\textsc{Insert} inserts to $T_1$ and then demotes elements from $T_1,T_2,\ldots$
until the forest is fixed.
\textsc{Delete} finds the pair in its tree $T_i$ and removes it, and
then promotes items from all trees $T_{i+1},T_{i+2},\ldots$
Since both \textsc{Insert} and \textsc{Delete} need to promote and demote items
in potentially every tree $T_i$, they both access $\O(\log N)$ nodes.

As in our description of splay trees, let $K$ be the set of keys,
let $\{k_i: i\leq M\}$ be the sequence of indices of accessed keys and
for any $j\in\{1,\ldots M\}$, let $t(j)$ be the number of distinct
keys accessed since the last access of key $K_{k_j}$.
\cite{martel} proves the following theorems analogous to desirable properties
of splay trees:
\begin{theorem}[Working Set Theorem for $k$-forests]
	With LRU demotion, the $j$-th lookup accesses $\O(\log_k t(j))$ nodes.
	With random demotion, it accesses expected $\O(\log_k t(j))$ nodes.
\end{theorem}

Again, let $q(K_i)$ be the number of accesses to $K_i$.
\begin{theorem}[Static Optimality Theorem for $k$-forests]
	Accessing a sequence of keys $\{K_{k_i}: i\leq M\}$ requires
	$\O(\sum_{i=1}^N q(K_i) \log_k \frac{M}{q(K_i)})$ node accesses.
\end{theorem}

We implemented $k$-forests with random demotion to benchmark their performance,
especially to examine the constant multiplicative factors taken by promoting
and demoting in every operation. Compared to $k$-splay trees, $k$-forests
also provide better asymptotic bounds on the number of transfers per operation,
so we wanted to see which choice is faster in practice.

\section{Related results}
\cite{alternatives-to-splay-trees} and \cite{unified-access-bound} extend
$k$-forests to build data structures with the \emph{unified property},
which is a strong generalization of the dynamic finger property and the working
set property of splay trees.
It is not known whether splay trees also have the unified property.
The data structure from \cite{alternatives-to-splay-trees} also improves
upon splay trees by guaranteeing a worst-case access time of $\O(\log N)$.
Unfortunately, the structure (as described by the authors) is static and highly
complex: each node of the structure stores 21 pointers.

\cite{dynamic-optimality-for-sl} uses a similar doubly exponential construction
to build a self-adjusting skip list. Operations on this skip list take time
$\O(\log t(j))$, which matches the working set bound on splay trees.
This structure is also shown to be dynamically optimal among skip lists
constrained by some restrictions (e.g.,\ allowing at most $b$ consecutive
forward steps on any level for a fixed $b$), which implies that this
restriction of skip lists does not allow better performance than
$\O(\log t(j))$.
Skip lists in this \emph{SL-B model} can be simulated in B-trees via
a construction from \cite{exploring-duality}. This representation yields
a B-tree that is dynamically optimal within a restricted class in the external
memory model. We are not aware of any implementations or benchmarks of this
data structure.
% TODO: more?
