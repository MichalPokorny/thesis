\documentclass[a4paper]{article}
\usepackage[nottoc,numbib]{tocbibind}
\usepackage[utf8]{inputenc}
\usepackage[czech]{babel}

\begin{document}

\title{Efektivní implementace slovníků v RAM}
\author{Michael Pokorný}

\def\O{\mathcal{O}}
\def\Cpp{C++}

\maketitle
\tableofcontents

\section{Úvod}
Slovník patří mezi nejvíce používané datové struktury.
Jejich účel je spravovat konečnou množinu dvojic $\{(k_i,v_i)\}$,
kde $k_i$ se označují jako \textit{klíče} a $v_i$ se označují
jako \textit{hodnoty}. Klíče a hodnoty jsou prvky \textit{univerza
klíčů} $U_K$, resp. \textit{univerza hodnot} $U_V$. Klíče, respektive
hodnoty uložené ve slovníku označíme jako $K, V$. Počet dvojic uložených
ve slovníku si označme jako $N$.

Žádný klíč se nesmí ve slovníku opakovat, proto slovníky reprezentují
funkce z $K$ do $V$.

Typické rozhraní slovníku tvoří následující funkce:
\begin{itemize}
\item \textsc{Find($k$)}
	nalezne k danému klíči $k$ příslušnou hodnotu $v$, nebo oznámí,
	že žádná taková hodnota neexistuje.

\item \textsc{Insert($k$,$v$)}
	vloží do slovníku dvojici $(k,v)$.

\item \textsc{Delete($k$)}
	ze slovníku odstraní dvojici s klíčem $k$, nebo oznámí,
	že žádná taková dvojice neexistuje.
\end{itemize}

TODO priklady pouziti slovniku

\subsection{Rozšíření slovníku}
Je-li definované uspořádání nad univerzem klíčů, pro některá použití
je užitečné rozšířit slovník o následující funkce:
\begin{itemize}
\item \textsc{Successor($k$)}
	vrátí nejmenší klíč větší než $k$, který je uložený ve slovníku.
\item \textsc{Predecessor($k$)}
	naopak vrátí nejvyšší uložený klíč menší než $k$.
\end{itemize}

TODO pro ktera pouziti se to hodi?

Slovníky mohou k jednomu klíči ukládat více hodnot (například v případě
standartní knihovny \Cpp šablona \texttt{std::multimap}). V takovém případě
\textsc{Find} umožňuje iterovat nad všemi hodnotami příslušejícími ke klíči a
\textsc{Delete} maže pouze jeden pár $(k,v)$.

\subsection{Triviální implementace}
\subsubsection{Pole párů klíč-hodnota}
TODO obrazek

Jednoduchý slovník lze implementovat jako prosté pole párů $(k_i,v_i)$,
avšak taková implementace je velmi pomalá:
\begin{itemize}
\item \textsc{Find}
	má asymptotickou složitost $\O(N)$.
\item \textsc{Insert}
	může být implementovaný s asymptotickou složitostí $\O(1)$
	pomocí udržování odkazu na konec slovníku.
\item \textsc{Delete}
	musí mít složitost $\O(N)$, aby v poli nevznikaly díry --
	všechny dvojice za smazaným párem musí být posunuty doleva.
\end{itemize}

TODO a co spojovy seznam? unrolled linked list?

\subsubsection{Přímá adresace}
Je-li množina $U_K$ dostatečně malá, lze klíče interpretovat jako
adresy v paměti. Na adrese $k_i$ pak uložíme buď hodnotu $v_i$, nebo
značku, že žádná taková hodnota ještě neexistuje.

TODO obrazek

\textsc{Find}, \textsc{Insert} i \textsc{Delete} jsou pak operace s konstantní
časovou složitostí -- stačí jenom provést jednu dereferenci.
Tento přístup je bohužel málokdy praktický, protože univerzum klíčů $U_K$
je příliš velké na to, aby bylo možné alokovat $\O(|U_K|)$ místa.

\section{Hashování}
Hashování spočívá v \uv{kompresi} množiny $U_K$ do menší množiny $H$ pomocí
takzvané \textit{hashovací funkce} $h: U_K\rightarrow H$.
$H$ je přitom zvolena dost malá na to, aby bylo možné prvky $H$ indexovat
paměť. Protože $H$ je menší než $U_K$, nutně musí být přípustné, aby
více klíčů mělo stejnou hodnotu $h(k)$ (\textit{hash}).

Slovníky použivající hashování se jmenují \textit{hashovací tabulky}.
Informaci o tom, jaká hodnota přísluší klíči $k$, uložíme
v tabulce na indexu $h(k)$ jako pár $(k,v)$.

Operaci \textsc{Find} provedeme tak, že hashovací funkcí \textit{zahashujeme}
hledaný klíč a podíváme se, jaké páry jsou v hashovací tabulce uloženy
na výsledném indexu. Pokud některý z nich má hledaný klíč, vrátíme v něm
uloženou hodnotu.

Má-li více uložených dvojic stejný hash klíče, nastane takzvaná \textit{kolize}.
Existuje několik přístupů k řešení kolizí. Každý z nich přináší další
časovou náročnost, proto je žádoucí, aby funkce $h$ vracela prvky $H$
v přibližně uniformní distribuci.

Nastává-li příliš mnoho kolizí nebo je-li hashovací tabulka příliš málo
obsazená (a tedy paměťově neefektivní), můžeme provést \textit{přehashování} --
zvolíme novou množinu $H'$ a v čase $O(|H'|+|H|+N)$ vytvoříme novou hashovací
tabulku.

Přehashování udržuje zaplněnost hashovací tabulky uvnitř zvolených mezí
(například 50\%-90\%), které zaručují, že se neplýtvá pamětí a že kolize
nezpomalují vyhledávání.
Nová velikost hashovací tabulky se obvykle volí jako poměrný násobek předchozí
velikosti -- například $1/2\times$ při zmenšení a $2\times$ při zvětšení.

Díky tomuto exponenciálnímu zvětšování a zmenšování můžeme po každém vložení
nebo vymazání prvku zkontrolovat zaplněnost tabulky a případně přehashovat bez
podstatných důsledků v časové složitosti. Složitost přehashování lze totiž
amortizovat jako $\O(1)$ v okamžiku přidání prvku do tabulky.
TODO ukazat

\subsection{Kolizní seznam}
Každý index v hashovací tabulce obsahuje spojový seznam všech dvojic, jejichž
klíč má daný hash. Operace \textsc{Find}, \textsc{Delete} a \textsc{Insert}
tento seznam celý projdou. Problém tohoto přístupu spočívá především v
\textit{indirekci} - prvky spojových seznamů obsahují odkazy
na následující prvky, které musí být dereferencovány. Dereference
je pomalá operace. TODO

\subsection{Dvojité hashování}
\subsection{Otevřená adresace}
\subsection{Kukaččí hashování (\textit{cuckoo hashing})}


\section{Vyhledávací stromy}

\section{Slovníkové struktury pro externí paměť}

TODO: cela sekce \cite{Vit}

Externí hashování pro online slovníkové vyhledávání

Operace: insert, delete, find

Hlavní typy pro externí paměť: hashování, stromy

Hashování: máme predefinovanou $h:Keys\rightarrow\{0\cdots K-1\}$.
Liší se handling kolizí.

Cíl: průměrně chceme $\O(Output(Z))=\O(\lceil z\rceil)$
I/O na lookup, kde vyhledávám $Z$ itemů. $B$ je počet itemů v bloku.
$Z=zB$. Chci $\O(1)$ I/O na insert/delete, lineární space.

Tradiční metody: statická tabulka, takže maximálně fixed range $N$.
Chci smooth adaptation to varying values. Je dost neoptimální
to zvětšovat a zmenšovat.

\subsection{Directory hashing methods}
TODO: Fagin et al citace (144 ve clanku)

Extendible hashing.
Directory pro $d\geq 0$ je tabulka $2^d$ pointerů.
Každý item je daný na to místo v tabulce, které patří $d$ prvním bitům jeho
hashe.
$d$ = global depth, nastavím na nejmenší hodnotu, kde má každé místo v tabulce
nejvýše $B$ prvků (čili se vejdu do bloku).
Každý prvek slovníku obsahuje pointer do bloku, kde jsou jeho data.
Lookup tedy bere jedno I/O za slovník a jedno I/O za disk. (Jenom jedno vejde-li
se slovník do paměti.)
(Tady bude zajímavé zkoušet ten slovník komprimovat.)

Některé kyblíky mají míň než $B$ položek. Abych zmenšil space usage, můžou
ukazovat na stejný blok.
Sdílí diskový blok se všemi ostatními kyblíky, co mají stejných $k$ prvních bitů
adresy ($k\geq d$). $k$ minimalizuju dokud můžu. Každý blok má jinou lokální
hloubku.

Když přeteče disk block, přepočítám globální a lokální hloubku.
Neboli "rozdělím" blok, který přetekl, a předistribuuju jeho položky.
Pokaždé když zvětším o 1 globální hloubku, zdvojnásobí se slovník. Takhle se
adaptuju na rostoucí $N$. (Můžu mít velká uložená data.)
Všimni si taky, že když přeteču, nemusím měnit bloky, které zrovna nepřetekly,
což je super.
Všimni si, že když nestačí změnit globální hloubku, může být potřeba změnit i tu
lokální.

Když dva bloky se stejnou lokální hloubkou obsahují položky, které mají stejných
$k-1$ prvních bitů a vejdou se dohromady, zmerguju je a zmenším lokální hloubku.
Musí být dohromady dost malé na to, aby se při dalším insertionu hned zase
nerozbily. TODO: o kolik?

Jakmile jsou všechny lokální hloubky méně než $d$, rozpůlím slovník.

TODO: slozitosti, prumerne pocty atd.

Je to vlastně trie s rychlým přístupem.

Jakmile je slovník mimo cache, mám 2 I/O :(

Taky existuje linearni hashovani. TODO: strana 38/80

\subsection{Directoryless hashing methods}

\section{Tree EM structures}

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}
